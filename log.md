

## Day 0: 
**Today's Progress**: Forked this repositorty and read the rules thoroughly and thought about projects

**Thoughts:**  I was first white boarding ideas to showcase and prove my dailey work. As I was connecting to my repository I saw Siraj's repositorys and of course went with the flow (pun intended)

**Link to work:** https://github.com/HvyD/100-days-of-code


## Day 1: 
**Today's Progress**: Got my hands on a Intel Compute stick and wasted several hours trying to just install the software. The Intel stick if very picky on the Ubuntu version. I am running 18 but wants 16. The day was not all a loss I started doing Kaggles HR Analytics project to warm up to the big money competitions.

**Thoughts:**  I got alot done today on my HR project. The Dataset was cleaned and preprocessed and I ran it through a descison tree with poor results. I need to think of another algorithm to use. Maybe something Gradient or a Random Forest.

**Link to work:** https://github.com/HvyD/Kaggle---IBM-Analytics/blob/master/IBM%20HR%20Analytics%20Project.ipynb


## Day 2: 
**Today's Progress**: I worked on the Kaggle IBM HR proect. I used gradient boosting classifier which got me in the high ninety percentile on both the training and test sets. Better results than yesterdays overfitting using a decision tree. I also played around with Seaborn with Matplotlib to view my model results better.

**Thoughts:**  After watching Siraj's new recent video on Backproppagation I had gradient decent stuck in my head, so I tried using a gradient technique for this project.

**Link to work:** https://github.com/HvyD/Kaggle---IBM-Analytics


## Day 3: 
**Today's Progress**: Today was another productive day. I found a good ML dataset repostory and used a Breast Cancer Dataset to build and run a K-Nearest Nieghbor model For fun  I fitted and scored the dataset through a SVM, Random Forest and XGBoost models. I also figured out how to streamline my Exploratory Data Analysis with more logical approach to importing and assigning column labels.

**Thoughts:**  I definetly like the UCI ML repository to practice on. I am still treading on the fundamentals for now to gain some inspiration to continue my Deep Learning and Artificial Intellegence work.


**Link to work:** https://github.com/HvyD/UCI-Breast-Cancer-Detection-Dataset-Project



## Day 4: 
**Today's Progress**: Today I used Tensorflow to add a DQN model to my AI DOOM player agent that I had built a awhile back that had orignally only used a basic score based heuristics. 

**Thoughts:**  Using Deep models and Reinforcement techniques really work great with retro games. Im wrapping my mind around more recent and advance applications. 

**Link to work:** https://github.com/HvyD/Artificial-Intelligent-Doom-player



## Day 5: 
**Today's Progress**: Today I decided to build a RNN model without using any libraries only Numpy for the calculations. 

**Thoughts:** I really was able to wrap my mind around the inner workings of a model and especially Forward and Back propagation. Tommororw I will build an LSTM to add to it and hopfully I will be pushing some Data through it the following day.

**Link to work:** https://github.com/HvyD/RNN-LSTM-No-Libraries-



## Day 6: 
**Today's Progress**: Today I continued to work on my RNN-LSTM Network from scratch by adding the LSTM Layer.

**Thoughts**:  Im really grasping statistical thinking. Tommorrow I will try my network on some Sequential Data.

**Link to work**: https://github.com/HvyD/RNN-LSTM-without-Libraries


## Day 7: 
**Today's Progress**: Today I finished work on my RNN-LSTM Network from scratch by feeding 'The Goonies' movie script through it and got great predictions.

**Thoughts**:  Today was the fun part of ML being able to actually run my Model. Building models from scratch is tedious and time consuming. Unless you need to tweak some deminsion I suggest using a library. 

**Link to work**: https://github.com/HvyD/RNN-LSTM-without-Libraries



## Day 8: 
**Today's Progress**: Today I went further.... I took a LSTM model using Keras and generated 'Metallica' style music.

**Thoughts**:  I really like the ease of libraries like Keras and Tensorflow. 

**Link to work**: https://github.com/HvyD/Generating-Metallica-style-music-with-a-LSTM



## Day 9: 
**Today's Progress**: Today I made a Movie Recommender System from Scratch to brush up on my math. I only used Numpy and Scipy for importation of the data files. On a less ML note I taught a youngster about Classes and Functions in Python using the Turtle library.

**Thoughts**:  I really like the recommended movies. Its almost like my model is intuitive...

**Link to work**: https://github.com/HvyD/Movie-Recommender-System



## Day 10: 
**Today's Progress**: Today I brushed up on DCGAN's by building a model with pytorch and used the cifar-10 dataset.

**Thoughts**:  It took awhile to run my model. In the future I might think about not being lazy and running my model on a cloud GPU. I also want to find a cool dataset to run through it. This might be my Finally project at the end of the 100 days.

**Link to work**: https://github.com/HvyD/Deep-Convolutional-GANs



## Day 11: 
**Today's Progress**: Today I was mostly AFK, but that didn't stop me. I read some "Hands-On Machine Learning with SciKit-Learn & TensorFlow" an O'Reilly book. My DCGAN's model is still trainning, too.

**Thoughts**:  Good book so far. It really describes Machine Algorithms in basic terms. I am excited to try the examples later in the book.

**Link to work**: http://shop.oreilly.com/product/0636920052289.do & https://github.com/HvyD/Deep-Convolutional-GANs


## Day 12: 
**Today's Progress**: Today I finally finished trainning my DCGAN's. I also messed around with Keras and had fun with Keras's Datasets with some basic models.

**Thoughts**:  I'm not happy with my DCGAN's results. I am leaning towards a hardware optimization problem not a Data or Model issue. Since I trainned it on my CPU rig. On a lighter note I really like the summary() print out that Keras does.

**Link to work**: https://github.com/HvyD/Fun-with-Keras


## Day 13: 
**Today's Progress**: Today I started the Metis Challenge of Naive-Bees from DataDriven on DataCamp

**Thoughts**:  I like using PIL. Opening and manipulating photo files are easy..

**Link to work**: https://github.com/HvyD/NAIVE-BEES



## Day 14: 
**Today's Progress**: Today I made a self-driving car Detector system using YOLO. I also pondered about models I can throw at the Naive-Bees challenge.

**Thoughts**: I like the YOLO algorithm over Haar, Cascading and Violo-Jones.

**Link to work**: https://github.com/HvyD/DeepLearinig_Autonomous_Driving-Detector



## Day 15: 
**Today's Progress**: Today I played with some more Computer Vision Techniques and Algorithms. I Applied Haar using OpenCV and pytorch to an Object Detector and a Facial reconizer.

**Thoughts**: OpenCV seems to be a pretty nice Computer Vision Library.

**Link to work**: https://github.com/HvyD/Facial_Recon-Detection_using_Haar




## Day 16: 
**Today's Progress**: Today I made a CNN for a Autonomus Training system with TensorFlow that using images from cams and Lidar. I also looked at "Parcey Mcparseface" for a future Book Automation reader and Summary writer project.

**Thoughts**: TensorFlow is my new go to library, lately... And the Google Developers must have to much time on their hands or need to share the drugs the are doing because these APi names are getting out there...

**Link to work**: https://github.com/HvyD/Autonomous-Training-System



## Day 17: 
**Today's Progress**: Today I added Optical Flow to My Autonomous System. I used OpenCV to aquire the Video and Images from a cam for Neural Training.

**Thoughts**: Using OpenCv was fun and easy.

**Link to work**: https://github.com/HvyD/Autonomous-Training-System




## Day 18: 
**Today's Progress**: Today I made a Security Log Analyzer with SciKit-Learn using a KNN model.

**Thoughts**: Cyber Seccurity is Stimulating. Tomorrow I will finish my Malicious URL Detector

**Link to work**: https://github.com/HvyD/Security_Log-Analyzer



## Day 19: 
**Today's Progress**: Today I made a malicious URL detector using Keras with a Convolutional and LSTM model.

**Thoughts**: I really enjoy going through data and preparing it. Its feels like Sherlock Holmes on an Adventure.

**Link to work**: https://github.com/HvyD/Malicious-URL-Detector




## Day 20: 
**Today's Progress**: Today I continued to use Keras and I Built a LSTM model that predicts Currency prices.

**Thoughts**: I like the ease of Tensorflows back end with Keras. I am Suprised how close my predictions are on the Bitcoin Dataset I used. Hec, I might want to gamble on some Crypto-Currency in the near future.

**Link to work**: https://github.com/HvyD/Currency-Predictor




## Day 21: 
**Today's Progress**: Today I made a Convolutional Autoencoder for Medical Imaging.

**Thoughts**: Really big Datasets. Definiely needs GPU used.

**Link to work**: https://github.com/HvyD/Medical-Image-Reconstruction-with-Convolutional-AutoEncoder




## Day 22: 
**Today's Progress**: Today I made a Fake News Detector using NLP with a Naive Bayes and a Linear Model..

**Thoughts**: I really like using S3 buckets for the data and AWS instances really made the Natural Language Pipeline flow without any freezes.

**Link to work**: https://github.com/HvyD/Fake-News-Detector



## Day 23: 
**Today's Progress**: Today I worked on Kmeans Clustering and Linear Models for a MLB win predictor. Also dabbled with SQLite3 database to import the dataset.

**Thoughts**:  Using SQLite3 was fun. 

**Link to work**: https://github.com/HvyD/MLB-Team-Win-Predictor



## Day 24: 
**Today's Progress**: Today I decided to make lemonade out of all the rejection letters I have recieved this past year. I scraped all my rejection emails into a .CSV file and after exploring and feature selection I ran it through some NLP techniques on it pulling different comparisons. Showcasing with plots and WordClouds.  Lastly I ran the dataset through a RandomForest and AdaBoost model's. All this to poke fun at all the companies who declined my services.

**Thoughts**:  I found so new and cool functions with Pandas and had fun making WordClouds...

**Link to work**: https://github.com/HvyD/Rejection-Letter-Analysis
